<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Currency Detection</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- TensorFlow.js -->
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f4c3;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            color: #333;
        }

        .container {
            background-color: #ffffff;
            border-radius: 15px;
            box-shadow: 0px 8px 15px rgba(0, 0, 0, 0.1);
            padding: 30px;
            text-align: center;
            width: 90%;
            max-width: 600px;
        }

        video {
            border: 4px solid #00796b;
            border-radius: 10px;
            width: 100%;
            margin-bottom: 20px;
        }

        .capture-btn {
            background-color: #00796b;
            color: #fff;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 18px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        .capture-btn:hover {
            background-color: #004d40;
        }

        .footer {
            margin-top: 15px;
            font-size: 14px;
            color: #777;
        }

        .footer a {
            color: #00796b;
            text-decoration: none;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Currency Detection</h1>
        <p>Place the currency in front of the camera.</p>
        <video id="videoElement" autoplay></video>
        <button class="capture-btn" onclick="captureImages()">Capture Images</button>
        <canvas id="canvas" style="display: none;"></canvas>
        <div class="footer">
            <p>Powered by <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a></p>
        </div>
    </div>

    <script>
        // Initialize webcam
        let model; // To hold the loaded model
        let modelLoaded = false; // Flag to track model loading status

        // Start webcam function
        function startWebcam() {
            const videoElement = document.getElementById('videoElement');
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(stream => {
                        videoElement.srcObject = stream;
                    })
                    .catch(error => {
                        console.error("Error accessing webcam: ", error);
                        alert("Camera access denied or unavailable.");
                    });
            } else {
                alert("Your browser does not support webcam access.");
            }
        }

        // Function to capture images
        async function captureImages() {
            // Check if model is loaded before proceeding
            if (!modelLoaded) {
                alert('Model is not loaded yet. Please wait...');
                return; // Stop execution if model isn't loaded
            }

            speak("takingPicture");

            let predictions = []; // Array to store predictions from each image
            let captureCount = 0;

            // Function to capture and process a single image
            const captureImage = async () => {
                const canvas = document.getElementById('canvas');
                const videoElement = document.getElementById('videoElement');
                canvas.width = videoElement.videoWidth;
                canvas.height = videoElement.videoHeight;
                const context = canvas.getContext('2d');
                context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

                // Convert the captured image to base64 to send to the server
                const base64Image = canvas.toDataURL('image/jpeg');

                // Send the captured image to the server for prediction
                const response = await fetch('http://localhost:5000/predict', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ image: base64Image }),
                });

                const result = await response.json();
                predictions.push(result.prediction);

                captureCount++;

                // Fast 3-second capture
                if (captureCount < 3) {
                    setTimeout(captureImage, 300); // Capture next image every 300 ms for the first 3 seconds
                }
                // After 3 seconds, slow down the capture (change the delay to 1.3 seconds)
                else if (captureCount < 8) {
                    setTimeout(captureImage, 1300); // Capture next image after 1.3 seconds
                } else {
                    analyzePredictions(predictions); // Analyze the predictions after 8 captures
                }
            };

            // Start capturing images
            captureImage();
        }

        // Analyze the predictions from the 8 captured images
        function analyzePredictions(predictions) {
            const mostFrequentPrediction = getMostFrequentPrediction(predictions);
            const currencyValue = getCurrencyValue(mostFrequentPrediction);

            if (currencyValue) {
                speak("detectedValue");
                speak(currencyValue);
            } else {
                speak("notCurrency");
            }
        }

        // Function to get the most frequent prediction from the 8 images
        function getMostFrequentPrediction(predictions) {
            const frequency = {};
            let maxCount = 0;
            let mostFrequent = null;

            predictions.forEach(pred => {
                frequency[pred] = (frequency[pred] || 0) + 1;
                if (frequency[pred] > maxCount) {
                    maxCount = frequency[pred];
                    mostFrequent = pred;
                }
            });

            return mostFrequent;
        }

        // Helper function to map predicted class to a currency value
        function getCurrencyValue(predictedClass) {
            const currencyValues = {
                0: '10 INR',
                1: '100 INR',
                2: '20 INR',
                3: '200 INR',
                4: '50 INR',
                5: '500 INR',
            };
            return currencyValues[predictedClass] || null;
        }

        // Speech synthesis function for different languages
        let selectedLanguage = 'en'; // Default is English
        const messages = {
            en: {
                welcome: "Welcome! Please say 'Tamil' or 'English' to select your language.",
                notCurrency: "This is not a currency. Please provide the correct input.",
                moveRight: "Move the currency 2 inches to the right.",
                moveLeft: "Move the currency 2 inches to the left.",
                takingPicture: "The picture will be taken in rapid succession for the first 3 seconds, then 1 second intervals.",
                detectedValue: "The currency detected is",
            },
            ta: {
                welcome: "வணக்கம்! உங்கள் மொழியை தேர்வுசெய்ய தமிழ் அல்லது ஆங்கிலம் என கூறவும்.",
                notCurrency: "இது நோட்டாக இல்லை. சரியான உள்ளீட்டை தரவும்.",
                moveRight: "நோட்டுகளை 2 இன்ச் வலது பக்கம் நகர்த்தவும்.",
                moveLeft: "நோட்டுகளை 2 இன்ச் இடது பக்கம் நகர்த்தவும்.",
                takingPicture: "படம் 3 வினாடிகளில் விரைவாக எடுக்கப்படும், பிறகு 1 வினாடி இடைவெளியில்.",
                detectedValue: "பரிசுக்கான மதிப்பு ",
            }
        };

        // Speech synthesis function
        function speak(textType) {
            const speech = new SpeechSynthesisUtterance(messages[selectedLanguage][textType]);
            speech.lang = selectedLanguage === 'en' ? 'en-US' : 'ta-IN';
            speech.rate = 1;
            window.speechSynthesis.speak(speech);
        }

        // Change language function
        function changeLanguage(language) {
            selectedLanguage = language;
            speak('welcome');
        }

        // Start everything on page load
        window.onload = () => {
            startWebcam();
        };
    </script>
</body>

</html>
Key Changes:
API Call (fetch): Replaced the TensorFlow.js model loading part with an API request to your Python server (http://localhost:5000/predict). The image is sent as a base64 string.
Prediction Handling: The captureImage function now sends the image data to the server and processes the predicti
